{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10816368,"sourceType":"datasetVersion","datasetId":6715424}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport os\n\n# Define parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nDATASET_PATH = \"/kaggle/input/meow15\"  # Update this to your dataset path\nEPOCHS = 15\n\n# Load and preprocess dataset\ndatagen = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=40,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    DATASET_PATH,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\nval_generator = datagen.flow_from_directory(\n    DATASET_PATH,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Load pre-trained model (InceptionV3) and modify it\nbase_model = tf.keras.applications.InceptionV3(\n    input_shape=(*IMG_SIZE, 3), \n    include_top=False, \n    weights='imagenet'\n)\nbase_model.trainable = False  # Freeze the base model\n\n# Create a new classification head\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(len(train_generator.class_indices), activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Callbacks for better training\nearly_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    callbacks=[early_stopping, lr_scheduler]\n)\n\n# Fine-tune by unfreezing some layers\nbase_model.trainable = True\nfor layer in base_model.layers[:150]:  # Freeze first 150 layers\n    layer.trainable = False\n\n# Recompile the model with a lower learning rate\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Continue training\nhistory_fine = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    callbacks=[early_stopping, lr_scheduler]\n)\n\n# Save the fine-tuned model\nmodel.save(\"fine_tuned_inceptionv3.h5\")\nprint(\"Model training complete and saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T17:46:14.422265Z","iopub.execute_input":"2025-02-21T17:46:14.422726Z","iopub.status.idle":"2025-02-21T17:49:34.654418Z","shell.execute_reply.started":"2025-02-21T17:46:14.422681Z","shell.execute_reply":"2025-02-21T17:49:34.653174Z"}},"outputs":[{"name":"stdout","text":"Found 50 images belonging to 2 classes.\nFound 12 images belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7s/step - accuracy: 0.6815 - loss: 0.7344 - val_accuracy: 0.5833 - val_loss: 1.1450 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.5833 - val_loss: 1.3727 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6667 - val_loss: 0.5329 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.9681 - loss: 0.1734 - val_accuracy: 0.6667 - val_loss: 0.5853 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.6882e-05 - val_accuracy: 0.8333 - val_loss: 0.5096 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9167 - val_loss: 0.6222 - learning_rate: 0.0010\nEpoch 7/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.1349e-05 - val_accuracy: 0.6667 - val_loss: 1.1218 - learning_rate: 0.0010\nEpoch 8/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 1.2720e-05 - val_accuracy: 0.8333 - val_loss: 0.4165 - learning_rate: 5.0000e-04\nEpoch 9/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.0410e-06 - val_accuracy: 0.9167 - val_loss: 0.1027 - learning_rate: 5.0000e-04\nEpoch 10/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.8333 - val_loss: 0.7104 - learning_rate: 5.0000e-04\nEpoch 11/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.7513e-06 - val_accuracy: 0.8333 - val_loss: 0.2263 - learning_rate: 5.0000e-04\nEpoch 12/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0137 - learning_rate: 2.5000e-04\nEpoch 13/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.4366e-06 - val_accuracy: 0.9167 - val_loss: 0.1916 - learning_rate: 2.5000e-04\nEpoch 14/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0490e-07 - val_accuracy: 1.0000 - val_loss: 0.1226 - learning_rate: 2.5000e-04\nEpoch 15/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.5655e-05 - val_accuracy: 0.8333 - val_loss: 0.3131 - learning_rate: 1.2500e-04\nEpoch 1/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8s/step - accuracy: 0.9230 - loss: 0.2331 - val_accuracy: 0.9167 - val_loss: 0.5059 - learning_rate: 1.0000e-04\nEpoch 2/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.9867 - loss: 0.0339 - val_accuracy: 0.8333 - val_loss: 0.1795 - learning_rate: 1.0000e-04\nEpoch 3/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.9867 - loss: 0.0259 - val_accuracy: 0.9167 - val_loss: 0.3959 - learning_rate: 1.0000e-04\nEpoch 4/15\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 1.1964e-04 - val_accuracy: 1.0000 - val_loss: 0.0816 - learning_rate: 1.0000e-04\nModel training complete and saved!\n","output_type":"stream"}],"execution_count":1}]}